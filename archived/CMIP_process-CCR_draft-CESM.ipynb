{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocean thermal forcing -- Verjans refactored with xarray\n",
    "Clean ocean TF workflow for deployment on CCR.\n",
    "\n",
    "10 Oct 2024 | EHU\n",
    "- 15 Oct: try with CESM rather than IPSL, for now.  The [IPSL tripolar grid](https://cmc.ipsl.fr/international-projects/cmip5/ipsl-contribution-to-cmip5-faq/) is a complication to deal with in the next revision.\n",
    "- 16 Oct: CESM2 is successful (in 2000-2014 and 1950-1999 examples)! Next try implementing `xr.mfdataset`, or else a for loop, to include all historical data together.  MFdataset may complicate the write-out on GHub but could be good for CCR.\n",
    "- 24 Oct: Found that use of an unconventional fill value may have been messing with processing.  Removed fill value of 1.1e20 from the masking command `tf_out = fftf.where(gld_ds.thetao<1e10)` because xarray handles NaNs by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import copy\n",
    "import csv\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import dask\n",
    "from datetime import datetime\n",
    "\n",
    "from verjansFunctions import freezingPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings for this run\n",
    "saveBoxGreenlandNC = True\n",
    "cwd                = os.getcwd()+'/'\n",
    "\n",
    "SelModel = 'CESM2'\n",
    "\n",
    "DirThetaoNC = f'/home/theghub/ehultee/projects/cmipdata/files/'\n",
    "DirSoNC     = f'/home/theghub/ehultee/projects/cmipdata/files/'\n",
    "DirSaveNC   = f'{cwd}../data/'\n",
    "\n",
    "### Select experiment ###\n",
    "To2015hist                 = True\n",
    "To2100histssp585           = False\n",
    "To2100histssp126           = False\n",
    "\n",
    "if(To2015hist):\n",
    "    Experiments = ['historical']\n",
    "    DatesCut    = [2015]\n",
    "elif(To2100histssp585): \n",
    "    Experiments = ['historical','ssp585']\n",
    "    DatesCut    = [2015,2100]\n",
    "elif(To2100histssp126): \n",
    "    Experiments = ['historical','ssp126']\n",
    "    DatesCut    = [2015,2100]\n",
    "nExp          = len(Experiments)\n",
    "depthUnitConv = 1.0 #initialize depth unit converter\n",
    "\n",
    "### Limits of Greenland domain ###\n",
    "limN           = 86.0 ## degrees N latitude\n",
    "limS           = 57.0 ## degrees N latitude\n",
    "limE           = 4.0 ## degrees E latitude\n",
    "limW           = 274.0 ## degrees E latitude\n",
    "## CHECK: confirm that output shows up within this W-E box and not its E-W complement\n",
    "limDp          = 1200.0\n",
    "depthSubSample = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "nExp          = len(Experiments)\n",
    "depthUnitConv = 1.0 #initialize depth unit converter\n",
    "\n",
    "if(SelModel=='MIROCES2L'):\n",
    "    dim2d              = True\n",
    "    if(To2015hist):\n",
    "        ls_members     = [f'r{id}' for id in range(1,30+1)]\n",
    "    elif(To2100histssp585 or To2100histssp126):\n",
    "        ls_members     = [f'r{id}' for id in range(1,10+1)]\n",
    "    namelat            = 'latitude'\n",
    "    namelon            = 'longitude'\n",
    "    namez              = 'lev'\n",
    "    datesendhist       = np.array(['201412'])\n",
    "    if(To2100histssp585):\n",
    "        datesendssp585     = np.array(['210012'])\n",
    "    if(To2100histssp126):\n",
    "        datesendssp126     = np.array(['210012'])\n",
    "        \n",
    "if(SelModel=='IPSL-CM6A-LR'):\n",
    "    dim2d              = True\n",
    "    if(To2015hist):\n",
    "        ls_members     = [f'r{id}' for id in range(1,32+1)]\n",
    "        ls_members.remove('r2') #no r2 member for IPSLCM6A\n",
    "    elif(To2100histssp585 or To2100histssp126):\n",
    "        ls_members     = ['r1'] #,'r3','r4','r6','r14']\n",
    "    namelat            = 'nav_lat'\n",
    "    namelon            = 'nav_lon'\n",
    "    namez              = 'olevel'\n",
    "    datesRef           = [1850.0,2015.0,2040.0] \n",
    "    datesendhist       = np.array(['194912','201412'])\n",
    "    if(To2100histssp585):\n",
    "        datesendssp585     = np.array(['210012'])\n",
    "    if(To2100histssp126):\n",
    "        datesendssp126     = np.array(['210012'])\n",
    "\n",
    "else:\n",
    "    print(f'Error script not implemented yet for {SelModel}')\n",
    "\n",
    "# nMemb           = len(ls_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the files to be read "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ThetaFiles_test = []\n",
    "SoFiles_test = []\n",
    "for expt in Experiments:\n",
    "    fpath1 = DirThetaoNC+'thetao_Omon_{}_{}_'.format(SelModel, expt)\n",
    "    print(fpath1)\n",
    "    fpath2 = DirSoNC+'so_Omon_{}_{}_'.format(SelModel, expt)\n",
    "    th_temp = glob.glob(f'{fpath1}*.nc')\n",
    "    s_temp = glob.glob(f'{fpath2}*.nc')\n",
    "    ThetaFiles_test += th_temp ##concat the glob lists\n",
    "    SoFiles_test += s_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the list is not empty.  If it is, something has gone wrong in the directory access or in the generation of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ThetaFiles_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load using a `with`-statement, to release memory as much as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the paths of the `thetao` and `so` variables -- ensure they come from the same GCM (`SelModel`) and time period.  Use a `with` statement to read in, trim, and close the parent datasets.  This should leave us with the trimmed datasets `gld_ds` and `gld_so` to work with below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = [f for f in ThetaFiles_test if '2000' in f][0] ## thetao\n",
    "path1 = [f for f in SoFiles_test if '2000' in f][0] ## salinity\n",
    "\n",
    "## load in and trim thetao\n",
    "with xr.open_dataset(path0, chunks={'lev':10}) as ds:\n",
    "    ## trim to Greenland bounding box\n",
    "    include_lat = (ds.lat>=limS) & (ds.lat <=limN)\n",
    "    include_lon = np.logical_or(((ds.lon%360)<=limE),((ds.lon %360) >=limW)) \n",
    "    ## modulo 360 to account for lon going -180 to 180 or 0-360\n",
    "    \n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': True}): ## mitigate performance problem with slicing\n",
    "        gld_ds = ds.where(include_lat & include_lon, drop=True)\n",
    "\n",
    "## load and trim so\n",
    "with xr.open_dataset(path1, chunks={'lev':10}) as ds1:\n",
    "    ## trim to Greenland bounding box\n",
    "    include_lat = (ds1.lat>=limS) & (ds1.lat <=limN)\n",
    "    include_lon = np.logical_or(((ds1.lon%360)<=limE),((ds1.lon %360) >=limW))\n",
    "    \n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': True}): ## mitigate performance problem with slicing\n",
    "        gld_so = ds1.where(include_lat & include_lon, drop=True) ## trim to Gld\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gld_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the ocean thermal forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fp = xr.apply_ufunc(freezingPoint, gld_so.so, gld_so.lev, dask='parallelized',\n",
    "                   dask_gufunc_kwargs={'allow_rechunk':True})\n",
    "fftf = gld_ds.thetao - fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mask and apply a fill value\n",
    "tf_out = fftf.where(gld_ds.thetao<1e10) ## apply Vincent's fill value of 1.1e20\n",
    "## actually, just let xarray do its native processing with NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_out.assign_attrs(standard_name='TF',\n",
    "                    long_name='Ocean thermal forcing',\n",
    "                    # fillvalue=1.1e20,\n",
    "                    latbounds=[limS, limN],\n",
    "                    lonbounds=[limW,limE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "ds_temp = tf_out.to_dataset(name='TF')\n",
    "# ds_temp.TF.attrs = tf_out.attrs\n",
    "ds_out = ds_temp.assign_attrs(title='Ocean thermal forcing for {}'.format(SelModel),\n",
    "                             summary='TF computed following Verjans code, in a bounding' + \n",
    "                              ' box around Greenland, for ISMIP7 Greenland forcing',\n",
    "                             institution='NASA Goddard Space Flight Center',\n",
    "                             creation_date=now.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write NetCDF out\n",
    "Attempt a write-out of this file.  The regular grid version for matplotlib is estimated at 400 MB - should be possible.\n",
    "\n",
    "Note we can't use Vincent's `DatesCut` here, so try using the year tag from the input files instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '/home/theghub/ehultee/data/'\n",
    "year_tag = path0.strip('.nc').split('_')[-1] ## take the year tag from the GCM input (only one of the two input DS, but we have tried to make them match!)\n",
    "out_fn = out_path + 'tf-{}-{}-v4_no_intermed_compute.nc'.format(SelModel, year_tag)\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "with ProgressBar():\n",
    "    ds_out.to_netcdf(path=out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove later: check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy  # Map projections libary\n",
    "import cartopy.crs as ccrs  # Projections list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '/home/theghub/ehultee/data/'\n",
    "f_in = out_path + 'tf-{}-200001-201412-v4_no_intermed_compute.nc'.format(SelModel)\n",
    "\n",
    "ds_new = xr.open_dataset(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_tavg = ds_new.TF.mean(dim='time') \n",
    "## TODO: remember to re-run the above and name the output variable!\n",
    "tf_tavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_tavg.sel(lev=0.0).mean(skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = plt.axes(projection=ccrs.Robinson())\n",
    "tf_tavg.sel(lev=0.0).plot(ax=ax, transform=ccrs.PlateCarree(), x='lon', y='lat') ## specify x and y coordinates\n",
    "ax.coastlines(); ax.gridlines();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_tavg.sel(lev=0.0).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
